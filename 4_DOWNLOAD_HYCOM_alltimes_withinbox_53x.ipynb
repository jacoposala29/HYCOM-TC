{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aaff488",
   "metadata": {},
   "source": [
    "### Jacopo Sala \n",
    "### Download full time series of HYCOM (2011-2015) in selected box as netCDF file\n",
    "### GOFS 3.1: 41-layer HYCOM + NCODA Global 1/12Â° Reanalysis\n",
    "GLBb0.08-53.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd274224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "# from datetime import datetime as dtime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import os.path\n",
    "import webbrowser\n",
    "import time\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "from FUNCTIONS_HYCOM import set_regions, set_regions_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1765035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define start and end years\n",
    "start_year = 2011\n",
    "end_year = 2015\n",
    "var_names_download = ['water_temp', 'salinity']\n",
    "var_names = ['temperature', 'salinity']\n",
    "\n",
    "HYCOM_dir =      '/Users/jacoposala/Desktop/CU/3.RESEARCH/ARGO_analysis/TC_HYCOM/DATA/HYCOM_near_TC_53x_raw_box_NEW_BOX_EPacific/'\n",
    "HYCOM_save_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/ARGO_analysis/TC_HYCOM/DATA/HYCOM_near_TC_53x_pkl_box_Global_40S_50N/'\n",
    "download_dir = '/Users/jacoposala/Downloads/'\n",
    "url_prefix='http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/YEAR'\n",
    "file_prefix ='?var=VARIABLE&north=NORTH&west=WEST&east=EAST&south=SOUTH&horizStride=1&time='\n",
    "file_suffix='Thh%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4'\n",
    "\n",
    "z_level_star = '0'\n",
    "file_extension = '.nc4'\n",
    "hycom_levels = 28 # 28\n",
    "max_depth_index_sel = 28 #28 # 10 or 11 depth levels \n",
    "min_wind_knots = 64\n",
    "tag_file = 'HYCOM_53X'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516e2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EPacific', 'WPacific_3of3', 'WPacific_1of3', 'NorthAtlantic', 'WPacific_2of3']\n"
     ]
    }
   ],
   "source": [
    "# List all the regions\n",
    "\n",
    "# lat_max, lat_min, lon_max, lon_min for every region\n",
    "regions = set_regions()\n",
    "regions_tags = set_regions_tags(regions)\n",
    "print(regions_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a27f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change number between 0 and len(regions)-1 for running different regions (listed above)\n",
    "region_to_run = 0\n",
    "# Set coordinates based on region_to_run\n",
    "lat_min = regions[region_to_run][1]\n",
    "lat_max = regions[region_to_run][0]\n",
    "lon_min = regions[region_to_run][3]\n",
    "lon_max = regions[region_to_run][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02898dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def download_model_dataset_53(date, north, south, east, west, url_prefix, file_prefix, file_suffix, f_dir, file_extension):\n",
    "    date_to_download = pd.to_datetime(date)\n",
    "    year = str(date_to_download)[0:4]\n",
    "    month = str(date_to_download)[5:7]\n",
    "    day = str(date_to_download)[8:10]\n",
    "    hour = str(date_to_download)[11:13]\n",
    "    date = datetime(int(year), int(month), int(day), int(hour))\n",
    "    year = f\"{int(date_to_download.year):04d}\"\n",
    "    # The year at the beginning of the URL is not always consistent with the actual year of the data being downloaded:\n",
    "    # Each year \"folder\" includes files starts at 12 UTC on Jan 1, and goes to 9 UTC of Jan 1 of the following year\n",
    "    if (date_to_download.month == 1) & (date_to_download.day == 1) & (date_to_download.hour < 12):\n",
    "        year_prefix = f\"{int(date_to_download.year - 1):04d}\"\n",
    "    else:\n",
    "        year_prefix = year\n",
    "    month = f\"{int(date_to_download.month):02d}\"\n",
    "    day = f\"{int(date_to_download.day):02d}\"\n",
    "    file_suffix_hh = file_suffix.replace('hh', hour, 1)\n",
    "    file_prefix_coord = file_prefix.replace('NORTH', north, 1)\n",
    "    file_prefix_coord = file_prefix_coord.replace('SOUTH', south, 1)\n",
    "    file_prefix_coord = file_prefix_coord.replace('EAST', east, 1)\n",
    "    file_prefix_coord = file_prefix_coord.replace('WEST', west, 1)\n",
    "    url = '\"' + url_prefix + file_prefix_coord + year + '-' + month + '-' + day + file_suffix_hh + '\"'\n",
    "    name_download = year_prefix + file_prefix_coord + year + '-' + month + '-' + day + file_suffix_hh #'/Users/jacoposala/Downloads/data_' + year + file_extension\n",
    "    print(name_download)\n",
    "    name_download = name_download.replace('%3A', ':', 2)\n",
    "    print(url)\n",
    "    print(name_download)\n",
    "    # Download file\n",
    "    if not os.path.exists(HYCOM_dir + file_prefix_coord + year + month + day + file_suffix_hh + file_extension):\n",
    "        # Download file\n",
    "        !wget {url}\n",
    "        # Wait until the file is downloaded\n",
    "        while not os.path.exists(name_download):\n",
    "            time.sleep(1)\n",
    "        print('Download done!')\n",
    "        # ...then rename and move file\n",
    "        if os.path.isfile(name_download):\n",
    "            os.rename(name_download, HYCOM_dir + file_prefix_coord + year + month + day + file_suffix_hh + file_extension)\n",
    "        else:\n",
    "            print('Missing ' + name_download)\n",
    "        print('Renaming or warning done!')\n",
    "    # Open the file\n",
    "    dset_day = xr.open_dataset(f'{f_dir}{file_prefix_coord}{year}{month}{day}{file_suffix_hh}{file_extension}')\n",
    "    # Remove the file\n",
    "    #if os.path.isfile(f'{f_dir}{file_prefix}{year}{month}{day}{file_suffix_hh}{file_extension}'):\n",
    "    #    os.remove(f'{f_dir}{file_prefix}{year}{month}{day}{file_suffix_hh}{file_extension}')\n",
    "    print('Dataset open - ready to return')\n",
    "    return(dset_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35640f0",
   "metadata": {},
   "source": [
    "### Now download full HYCOM time series (2011-2015) within selected box\n",
    "#### Note: this might not work on jupyter, but it does work on spyder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9368b7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2014, 8, 16, 15, 0),\n",
       " datetime.datetime(2014, 8, 16, 18, 0),\n",
       " datetime.datetime(2014, 8, 16, 21, 0),\n",
       " datetime.datetime(2014, 8, 17, 0, 0),\n",
       " datetime.datetime(2014, 8, 17, 3, 0),\n",
       " datetime.datetime(2014, 8, 17, 6, 0),\n",
       " datetime.datetime(2014, 8, 17, 9, 0),\n",
       " datetime.datetime(2014, 8, 17, 12, 0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of time-dates that need to be downloaded\n",
    "# start = datetime(2011, 1, 1, 00, 00, 00)\n",
    "start = datetime(2014, 8, 16, 15, 00, 00)\n",
    "end = datetime(2014, 8, 17, 21, 00, 00)\n",
    "date_generated = [start + timedelta(hours=3*x) for x in range(0, (end-start).days*8)]\n",
    "\n",
    "date_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054383fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note: files are missing for 2014-12-31 12 UTC to 2015-01-10 00 UTC (probably in 2015 folder instead of the 2014 or something like that)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31ed2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jacoposala/Downloads\n"
     ]
    }
   ],
   "source": [
    "cd /Users/jacoposala/Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6320b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-08-16 15:00:00\n",
      "2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "\"http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\"\n",
      "2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "--2023-04-13 22:34:32--  http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "Resolving ncss.hycom.org... 144.174.97.9\n",
      "Connecting to ncss.hycom.org|144.174.97.9|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 200\n",
      "Length: 9880750 (9.4M) [application/x-netcdf4]\n",
      "Saving to: '2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4'\n",
      "\n",
      "2014?var=water_temp 100%[===================>]   9.42M  16.8MB/s    in 0.6s    \n",
      "\n",
      "2023-04-13 22:36:04 (16.8 MB/s) - '2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4' saved [9880750/9880750]\n",
      "\n",
      "Download done!\n",
      "Renaming or warning done!\n",
      "Dataset open - ready to return\n",
      "2014?var=salinity&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "\"http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014?var=salinity&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\"\n",
      "2014?var=salinity&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "--2023-04-13 22:36:05--  http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014?var=salinity&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "Resolving ncss.hycom.org... 144.174.97.9\n",
      "Connecting to ncss.hycom.org|144.174.97.9|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 200\n",
      "Length: 7364765 (7.0M) [application/x-netcdf4]\n",
      "Saving to: '2014?var=salinity&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4'\n",
      "\n",
      "2014?var=salinity&n 100%[===================>]   7.02M  13.4MB/s    in 0.5s    \n",
      "\n",
      "2023-04-13 22:38:08 (13.4 MB/s) - '2014?var=salinity&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T15:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4' saved [7364765/7364765]\n",
      "\n",
      "Download done!\n",
      "Renaming or warning done!\n",
      "Dataset open - ready to return\n",
      "2014-08-16 18:00:00\n",
      "2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T18%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "\"http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T18%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\"\n",
      "2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T18:00:00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "--2023-04-13 22:38:08--  http://ncss.hycom.org/thredds/ncss/GLBv0.08/expt_53.X/data/2014?var=water_temp&north=30.0&west=-150.0&east=-100.0&south=0.0&horizStride=1&time=2014-08-16T18%3A00%3A00Z&vertCoord=&addLatLon=true&accept=netcdf4\n",
      "Resolving ncss.hycom.org... 144.174.97.9\n",
      "Connecting to ncss.hycom.org|144.174.97.9|:80... connected.\n",
      "HTTP request sent, awaiting response... ^C\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-454f9a4f3406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbfr_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_prefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YEAR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbfr_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VARIABLE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamevar_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         bfr_dset = download_model_dataset_53(x, north = str(max(np.ceil(lat_max), np.floor(lat_max))), \n\u001b[0m\u001b[1;32m     19\u001b[0m                                              \u001b[0msouth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                              \u001b[0meast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlon_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlon_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d7f2338fa52a>\u001b[0m in \u001b[0;36mdownload_model_dataset_53\u001b[0;34m(date, north, south, east, west, url_prefix, file_prefix, file_suffix, f_dir, file_extension)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Wait until the file is downloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Download done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# ...then rename and move file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "for x in date_generated: # loop through all unique days \n",
    "    print(x)\n",
    "    for namevar_download,namevar in zip(var_names_download,var_names): # loop over variables (temp or salt)\n",
    "        #for i in np.arange(len(lat_max)):\n",
    "        #    ilon=lon_max[i]\n",
    "        #    ilat=lat_max[i]\n",
    "        ilon = lon_max\n",
    "        ilat = lat_max\n",
    "        # Download HYCOM data\n",
    "        # The year at the beginning of the URL is not always consistent with the actual year of the data being downloaded:\n",
    "        # Each year \"folder\" includes files starts at 12 UTC on Jan 1, and goes to 9 UTC of Jan 1 of the following year\n",
    "        if ((pd.to_datetime(x)).month == 1) & ((pd.to_datetime(x)).day == 1) & ((pd.to_datetime(x)).hour < 12):\n",
    "            bfr_url = url_prefix.replace('YEAR', str((pd.to_datetime(x)).year -1))\n",
    "        else:\n",
    "            bfr_url = url_prefix.replace('YEAR', str((pd.to_datetime(x)).year))\n",
    "        bfr_prefix = file_prefix.replace('VARIABLE', str(namevar_download)) \n",
    "        bfr_dset = download_model_dataset_53(x, north = str(max(np.ceil(lat_max), np.floor(lat_max))), \n",
    "                                             south = str(min(np.ceil(lat_min), np.floor(lat_min))), \n",
    "                                             east = str(max(np.ceil(lon_max), np.floor(lon_max))),\n",
    "                                             west = str(min(np.ceil(lon_min), np.floor(lon_min))),\n",
    "                                             url_prefix=bfr_url, file_prefix=bfr_prefix, \n",
    "                                             file_suffix=file_suffix, f_dir=HYCOM_dir, \n",
    "                                             file_extension = file_extension)\n",
    "\n",
    "        # Longitude is -180 + 180 already, so no need to re-project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e7f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42307183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5290c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201782dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80259ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5f234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4758e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee85b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8ffde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4da17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
