{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aaff488",
   "metadata": {},
   "source": [
    "### Jacopo Sala \n",
    "### Download time series of HYCOM forcing at the location of the selected events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd274224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "# from datetime import datetime as dtime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import glob\n",
    "import os.path\n",
    "import webbrowser\n",
    "import time\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "from FUNCTIONS_HYCOM import set_regions, set_regions_tags, find_timedelta64_index\n",
    "import pickle as pkl\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1765035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define start and end years\n",
    "# start_year = 2011\n",
    "# end_year = 2015\n",
    "start_date = '2011-01-01'\n",
    "end_date = '2015-12-31'\n",
    "\n",
    "#start_date = '2010-12-25'\n",
    "#end_date = '2011-01-01'\n",
    "\n",
    "# start_date = '2015-09-02'\n",
    "# end_date = '2015-11-30'\n",
    "\n",
    "# for each element in list, we have FILENAME, VARS and TYPE\n",
    "url_info = [['precip', 'var=precip', 'sea'],\\\n",
    "            ['TaqaQrQp', 'var=airtmp&var=vapmix&var=radflx&var=shwflx', 'sea'],\\\n",
    "            ['surtmp', 'var=surtmp', 'sea'],\\\n",
    "            ['uv-10m', 'var=wndnwd&var=wndewd', 'sec2'],\\\n",
    "            ['wndspd', 'var=wndspd', 'sec2'],\\\n",
    "            ['sfcprs', 'var=airprs', 'sec'],\\\n",
    "            ['dswsfc', 'var=dswflx', 'sea'],\\\n",
    "            ['dlwsfc', 'var=dlwflx', 'sea']]\n",
    "\n",
    "# url_info = [['sfcprs', 'var=airprs', 'sec'],\\\n",
    "#             ['dswsfc', 'var=dswflx', 'sea'],\\\n",
    "#             ['dlwsfc', 'var=dlwflx', 'sea']]\n",
    "# url_info = [['precip', 'var=precip', 'sea'],\\\n",
    "#             ['TaqaQrQp', 'var=airtmp&var=vapmix&var=radflx&var=shwflx', 'sea'],\\\n",
    "#             ['surtmp', 'var=surtmp', 'sea'],\\\n",
    "#             ['uv-10m', 'var=wndnwd&var=wndewd', 'sec2'],\\\n",
    "#             ['wndspd', 'var=wndspd', 'sec2']]\n",
    "\n",
    "# HYCOM_forcing_save_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/ARGO_analysis/TC_HYCOM/DATA/HYCOM_FORCING_for_each_event/'\n",
    "HYCOM_forcing_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/ARGO_analysis/TC_HYCOM/DATA/HYCOM_FORCING/REGIONS/'\n",
    "# download_dir = '/Users/jacoposala/Downloads/'\n",
    "\n",
    "url_prefix = 'https://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/'\n",
    "file_prefix = 'cfsv2-TYPE_YEAR_01hr_FILENAME.nc?VARS&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=TIMESTART&time_end=TIMEEND&timeStride=1'\n",
    "file_suffix = '&addLatLon=true&accept=netcdf4'\n",
    "\n",
    "file_extension = '.nc4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3cd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32464b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define function to download forcing data\n",
    "\n",
    "# def download_forcing_data(date, north, south, east, west, url_prefix, file_prefix, file_suffix, f_dir, file_extension):\n",
    "#     date_to_download = pd.to_datetime(date)\n",
    "#     year = str(date_to_download)[0:4]\n",
    "#     month = str(date_to_download)[5:7]\n",
    "#     day = str(date_to_download)[8:10]\n",
    "#     hour = str(date_to_download)[11:13]\n",
    "#     date = datetime(int(year), int(month), int(day), int(hour))\n",
    "#     year = f\"{int(date_to_download.year):04d}\"\n",
    "#     month = f\"{int(date_to_download.month):02d}\"\n",
    "#     day = f\"{int(date_to_download.day):02d}\"\n",
    "    \n",
    "#     # The year at the beginning of the URL is not always consistent with the actual year of the data being downloaded:\n",
    "#     # Each year \"folder\" includes files starts at 12 UTC on Jan 1, and goes to 9 UTC of Jan 1 of the following year\n",
    "#     if (date_to_download.month == 1) & (date_to_download.day == 1) & (date_to_download.hour < 12):\n",
    "#         year_prefix = f\"{int(date_to_download.year - 1):04d}\"\n",
    "#     else:\n",
    "#         year_prefix = year\n",
    "\n",
    "#     # Fill out the URL now\n",
    "#     file_suffix_hh = file_suffix.replace('hh', hour, 1)\n",
    "#     file_prefix_coord = file_prefix.replace('NORTH', north, 1)\n",
    "#     file_prefix_coord = file_prefix_coord.replace('SOUTH', south, 1)\n",
    "#     file_prefix_coord = file_prefix_coord.replace('EAST', east, 1)\n",
    "#     file_prefix_coord = file_prefix_coord.replace('WEST', west, 1)\n",
    "    \n",
    "#     # Assemble the URL\n",
    "#     url = '\"' + url_prefix + file_prefix_coord + year + '-' + month + '-' + day + file_suffix_hh + '\"'\n",
    "    \n",
    "#     name_download = file_prefix_coord + year + '-' + month + '-' + day + file_suffix_hh\n",
    "#     name_download = name_download.replace('%3A', ':', 2)\n",
    "#     print(url)\n",
    "#     print(name_download)\n",
    "#     # Download file\n",
    "#     if not os.path.exists(HYCOM_focring_save_dir + file_prefix_coord + year + month + day + file_suffix_hh + file_extension):\n",
    "#         # Download file\n",
    "#         !wget {url}\n",
    "#         # Wait until the file is downloaded\n",
    "#         while not os.path.exists(name_download):\n",
    "#             time.sleep(1)\n",
    "#         print('Download done!')\n",
    "#         # ...then rename and move file\n",
    "#         if os.path.isfile(name_download):\n",
    "#             os.rename(name_download, HYCOM_focring_save_dir + file_prefix_coord + year + month + day + file_suffix_hh + file_extension)\n",
    "#         else:\n",
    "#             print('Missing ' + name_download)\n",
    "#         print('Renaming or warning done!')\n",
    "#     # Open the file\n",
    "#     dset_day = xr.open_dataset(f'{f_dir}{file_prefix_coord}{year}{month}{day}{file_suffix_hh}{file_extension}')\n",
    "#     # Remove the file\n",
    "#     #if os.path.isfile(f'{f_dir}{file_prefix}{year}{month}{day}{file_suffix_hh}{file_extension}'):\n",
    "#     #    os.remove(f'{f_dir}{file_prefix}{year}{month}{day}{file_suffix_hh}{file_extension}')\n",
    "#     print('Dataset open - ready to return')\n",
    "#     return(dset_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c75f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /Users/jacoposala/Downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3ab1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of dates\n",
    "date_list_start = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Print the list of dates\n",
    "# print(date_list_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f080ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of dates\n",
    "date_list_end = pd.date_range(start=start_date + ' 23:00:00', end=end_date + ' 23:00:00')\n",
    "\n",
    "# Print the list of dates\n",
    "# print(date_list_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a109d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WPacific_2of3']\n"
     ]
    }
   ],
   "source": [
    "# List all the regions\n",
    "\n",
    "# lat_max, lat_min, lon_max, lon_min for every region\n",
    "regions = set_regions()\n",
    "regions_tags = set_regions_tags(regions)\n",
    "print(regions_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac44c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WPacific_2of3\n"
     ]
    }
   ],
   "source": [
    "for r,r_tag in zip(regions, regions_tags):\n",
    "    lat_min = r[1]\n",
    "    lat_max = r[0]\n",
    "    lon_min = r[3]\n",
    "    lon_max = r[2]\n",
    "#     time.sleep(30)\n",
    "    print(r_tag)\n",
    "    for itime_start, itime_end in zip(date_list_start, date_list_end):\n",
    "#         time.sleep(1)\n",
    "        for iinfo in url_info:\n",
    "            url_mid = file_prefix.replace('TYPE', str(iinfo[2]))\\\n",
    "            .replace('YEAR', str(itime_start.year))\\\n",
    "            .replace('FILENAME', str(iinfo[0]))\\\n",
    "            .replace('VARS', str(iinfo[1]))\\\n",
    "            .replace('NORTH', str(lat_max))\\\n",
    "            .replace('WEST', str(lon_min))\\\n",
    "            .replace('EAST', str(lon_max))\\\n",
    "            .replace('SOUTH', str(lat_min))\\\n",
    "            .replace('TIMESTART', itime_start.strftime('%Y-%m-%d %H:%M:%S').replace(' ','T').replace(':','%3A') + 'Z')\\\n",
    "            .replace('TIMEEND', itime_end.strftime('%Y-%m-%d %H:%M:%S').replace(' ','T').replace(':','%3A') + 'Z')\n",
    "            \n",
    "            url = url_prefix + url_mid + file_suffix\n",
    "            \n",
    "            subprocess.run(['wget', '-O' + HYCOM_forcing_dir + r_tag + '/' + r_tag + '_' + iinfo[0] + '_' + itime_start.strftime('%Y%m%d') + file_extension, url])\n",
    "        if itime_start.day == 1 and itime_start.month == 1:\n",
    "            time.sleep(3)\n",
    "            print('Starting' + itime_start.strftime('%Y'))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7076245",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a852a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD high-speed event information (lat, lon, time)\n",
    "\n",
    "# List all files across basins\n",
    "# folder_tags = ['WPacific_3of3', 'Indian']\n",
    "folder_tags = ['NorthAtlantic']#, 'EPacific', 'WPacific_1of3', 'WPacific_2of3', 'WPacific_3of3', 'SWPacific_1of2', 'SWPacific_2of2', 'Indian']\n",
    "HYCOM_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/ARGO_analysis/TC_HYCOM/DATA/6_HYCOM_near_TC_53x_pkl_NEW_BOX_postproc_/'\n",
    "# timesteps_per_day = 8\n",
    "number_of_days_before_event = 6\n",
    "number_of_days_after_event = 24\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in np.arange(len(folder_tags)):\n",
    "\n",
    "    HYCOM_dir_current = HYCOM_dir.replace('postproc_', 'postproc_' + str(folder_tags[i])) \n",
    "    files_in_dir = [j for j in sorted(glob.glob(HYCOM_dir_current + '*MLD.pkl'))]\n",
    "    files = files + files_in_dir\n",
    "    \n",
    "# Load first to initialize variables that will store them all\n",
    "new_dict = pkl.load(open(files[1], \"rb\"))\n",
    "# Add info from the rest\n",
    "datasets = []\n",
    "index = [] \n",
    "N = 0\n",
    "for ifile in np.arange(len(files)):\n",
    "    df = pkl.load(open(files[ifile], \"rb\"))\n",
    "    # \n",
    "    _, index = np.unique(df['time'], return_index=True)\n",
    "    df_unique_time = df.isel(time=index)\n",
    "    date_of_event = pd.to_datetime(df.sel_date.values, format='%Y-%m-%d %H:%M:%S').to_datetime64()\n",
    "    start_date_event = date_of_event - np.timedelta64(number_of_days_before_event, 'D')\n",
    "    end_date_event = date_of_event + np.timedelta64(number_of_days_after_event, 'D')\n",
    "\n",
    "    # Create new time axis (hourly)\n",
    "    time_new = pd.date_range(start_date_event, end_date_event, freq='1h')\n",
    "\n",
    "#         time_new = pd.date_range(df.time.values[0], df.time.values[0] + np.timedelta64(int(len(df.time.values)/timesteps_per_day), 'D'), freq='1h')\n",
    "    # Interpolation using new time axis just created\n",
    "    df_unique_time_interp = df_unique_time.interp(time=time_new)\n",
    "#         if len(df_unique_time_interp.time.values):\n",
    "#             print('Check what is wrong')\n",
    "#             ciao1\n",
    "#         print(df.time.values)\n",
    "#         df['time'] = time_new\n",
    "\n",
    "        \n",
    "    df_unique_time_interp[\"index_tag\"] = files[ifile].split(\"/\")[-1].split(\"event\")[0] + 'event_' + \\\n",
    "    files[ifile].split(\"/\")[-1].split(\"event\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    df_unique_time_interp['time_event_original'] = df_unique_time_interp.time\n",
    "    # save date_of_event\n",
    "    df_unique_time_interp['date_of_event'] = date_of_event\n",
    "\n",
    "    df_unique_time_interp = df_unique_time_interp.assign_coords(time=df_unique_time_interp.time.values - date_of_event)\n",
    "    df_unique_time_interp = df_unique_time_interp.assign_coords(index=N)\n",
    "    df_unique_time_interp = df_unique_time_interp.expand_dims('index')\n",
    "    N = N+1\n",
    "    \n",
    "    df_unique_time_interp = df_unique_time_interp.rename_dims({'time': 'delta_time'})\n",
    "    df_unique_time_interp = df_unique_time_interp.rename({'time': 'delta_time'})\n",
    "    \n",
    "    \n",
    "#     df_unique_time_interp = df_unique_time_interp.drop_dims('time')\n",
    "    datasets.append(df_unique_time_interp)\n",
    "    \n",
    "print('before combined') \n",
    "\n",
    "combined = xr.concat(datasets, dim='index')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13277192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: if the minimum it is not True: PROBLEM \n",
    "min(np.abs(combined.time_event_original.isel(delta_time=6*24).values - combined.date_of_event.values)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_netcdf('combined.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796195f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b8f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7a7235",
   "metadata": {},
   "source": [
    "sst = \n",
    "http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sea_2011_01hr_surtmp.nc?var=surtmp&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "precip = \n",
    "http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sea_2011_01hr_precip.nc?var=precip&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "surface downwelling shortwave flux = \n",
    "http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sea_2011_01hr_dswsfc.nc?var=dswflx&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "surface downwelling longwave flux = \n",
    "http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sea_2011_01hr_dlwsfc.nc?var=dlwflx&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "air temperature &specific humidity & surface net downward radiative flux & surface net downward shortwave flux= http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sea_2011_01hr_TaqaQrQp.nc?var=airtmp&var=radflx&var=shwflx&var=vapmix&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "eastward wind & northward wind = \n",
    "http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sec2_2011_01hr_uv-10m.nc?var=wndewd&var=wndnwd&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "wind speed = \n",
    "http://ncss.hycom.org/thredds/ncss/datasets/force/ncep_cfsv2/netcdf/cfsv2-sec2_2011_01hr_wndspd.nc?var=wndspd&north=NORTH&west=WEST&east=EAST&south=SOUTH&disableProjSubset=on&horizStride=1&time_start=2011-01-01T00%3A00%3A00Z&time_end=2011-01-01T23%3A00%3A00Z&timeStride=1&addLatLon=true&accept=netcdf4\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6957e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f6584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc454c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a168430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96227390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbce9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a1817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42307183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5290c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201782dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80259ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5f234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4758e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee85b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8ffde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4da17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
